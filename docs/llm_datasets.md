---
hide:
  - feedback
tags:
  - LLMSecOps
  - Наборы данных
---

# Данные

| Ресурс | Описание |
|--------|----------|
| [Безопасность и конфиденциальность больших языковых моделей](https://github.com/annjawn/llm-safety-privacy) | GitHub-репозиторий по безопасности и конфиденциальности больших языковых моделей |
| [Взлом больших языковых моделей](https://github.com/verazuo/jailbreak_llms/tree/main/data) | Данные для взлома больших языковых моделей |
| [Системный промпт ChatGPT](https://github.com/LouisShark/chatgpt_system_prompt) | Репозиторий, содержащий системные промпты ChatGPT |
| [Do Not Answer](https://github.com/Libr-AI/do-not-answer) | Проект, связанный с контролем ответов больших языковых моделей |
| [ToxiGen](https://github.com/microsoft/ToxiGen) | Набор данных Microsoft |
| [SafetyPrompts](https://safetyprompts.com/) | Живой каталог открытых наборов данных для обеспечения безопасности больших языковых моделей |
| [llm-security-prompt-injection](https://github.com/sinanw/llm-security-prompt-injection) | Этот проект исследует безопасность больших языковых моделей путем выполнения бинарной классификации набора входных промптов для обнаружения вредоносных промптов. Были проанализированы несколько подходов с использованием классических алгоритмов машинного обучения, обученной модели большой языковой модели и тонко настроенной большой языковой модели. |
