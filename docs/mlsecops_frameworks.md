---
hide:
  - feedback
tags:
  - Frameworks
  - MlSecOps
---

## **Зарубежные**

| Название фреймворка | Описание | Ссылка |
| -------- | -------- | ------ |
| **OWASP ML TOP 10** | Фреймворк, описывающий топ 10 угроз для машинного обучения: отравление, уклонение и т.д. | [owasp.org/www-project-machine-learning-security-top-10/](https://owasp.org/www-project-machine-learning-security-top-10/) |
| **OWASP Top 10 for Large Language Model Applications** | Фреймворк, описывающий угрозы и митигейшоны для LLM приложений. | [owasp.org/www-project-top-10-for-large-language-model-applications/](https://owasp.org/www-project-top-10-for-large-language-model-applications/) |
| **databricks framework ai security(DASF)** | Фреймворк, описывающий угрозы на разных этапах процесса безопасной разработки машинного обучения. | [databricks.com/blog/introducing-databricks-ai-security-framework-dasf](https://www.databricks.com/blog/introducing-databricks-ai-security-framework-dasf) |
| **Mitre Attlas** | Фреймворк от Mitre, представленный ввиде матрицы угроз для машинного обучения и митигации. | [atlas.mitre.org/](https://atlas.mitre.org/) |
| **Nist Adversarial Machine Learning A Taxonomy and Terminology of Attacks and Mitigations** | Фреймворк от Nist, систематизирующий знания по состязательным атакам, а также их таксономию. | [nvlpubs.nist.gov/nistpubs/ai/NIST.AI.100-2e2023.pdf](https://nvlpubs.nist.gov/nistpubs/ai/NIST.AI.100-2e2023.pdf) |
| **AI Risk Assessment for ML Engineers** | Документ, позволяющий оценить зрелость организации при построении безопасного машинного обучения. | [learn.microsoft.com/en-us/security/ai-red-team/ai-risk-assessment](https://learn.microsoft.com/en-us/security/ai-red-team/ai-risk-assessment) |
| **Gartner AI Trust, Risk, and Security Management (AI TRiSM)** | Фреймворк, выпущенный Gartner, охватывающий такие проблемы как целостность, предвзятость, конфиденциальность, объяснимость. | [learn.microsoft.com/en-us/security/ai-red-team/ai-risk-assessment](https://www.gartner.com/en/articles/what-it-takes-to-make-ai-safe-and-effective) |
| **IBM Framework for Securing Generative AI** | Фреймворк, для защиты Generative AI. | [learn.microsoft.com/en-us/security/ai-red-team/ai-risk-assessment](https://www.ibm.com/blog/announcement/ibm-framework-for-securing-generative-ai/) |

...

